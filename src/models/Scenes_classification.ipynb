{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LJWafpx6Stq",
        "outputId": "6ee5508f-287b-4e3e-89e0-67a7f02c3c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us9KMH1aqy5j"
      },
      "source": [
        "#### Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgmNWu5yqy5l"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxdT9mXXqy5m"
      },
      "source": [
        "#### Cố định giá trị ngẫu nhiên"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ywssUSwqy5m"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed = 59\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWDU8H1rqy5m"
      },
      "source": [
        "#### Đọc dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMwP1O9Yqy5m"
      },
      "outputs": [],
      "source": [
        "root_dir = '/content/drive/MyDrive/AIO2024/M06/W02/Data/scenes_classification'\n",
        "train_dir = os.path.join(root_dir, 'train')\n",
        "test_dir = os.path.join(root_dir, 'val')\n",
        "classes = {\n",
        "    label_idx: class_name for label_idx, class_name in enumerate(sorted(os.listdir(train_dir)))\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7xeIffrqy5n"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for dataset_path in [train_dir, test_dir]:\n",
        "    for label_idx, class_name in classes.items():\n",
        "        class_dir = os.path.join(dataset_path, class_name)\n",
        "        for img_filename in os.listdir(class_dir):\n",
        "            img_path = os.path.join(class_dir, img_filename)\n",
        "            if 'train' in dataset_path:\n",
        "                X_train.append(img_path)\n",
        "                y_train.append(label_idx)\n",
        "            else:\n",
        "                X_test.append(img_path)\n",
        "                y_test.append(label_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVBkoQhdqy5n"
      },
      "source": [
        "#### Chia bộ dữ liệu train, val, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1b_JLQ6qy5n"
      },
      "outputs": [],
      "source": [
        "seed = 0\n",
        "val_size = 0.2\n",
        "is_shuffle = True\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train,\n",
        "    test_size=val_size,\n",
        "    random_state=seed,\n",
        "    shuffle=is_shuffle\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK-AWudUqy5n"
      },
      "source": [
        "#### Class pytorch datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VGop1Ikqy5n"
      },
      "outputs": [],
      "source": [
        "class ScenesDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.transform = transform\n",
        "        self.img_paths = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.labels[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1r3lXRqy5n"
      },
      "source": [
        "#### Xây dựng hàm tiền xử lý ảnh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tR5N3Quqy5n"
      },
      "outputs": [],
      "source": [
        "def transform(img, img_size=(224, 224)):\n",
        "    img = img.resize(img_size)\n",
        "    img = np.array(img)[..., :3]\n",
        "    img = torch.tensor(img).permute(2, 0, 1).float()\n",
        "    normalized_img = img / 255.0\n",
        "    return normalized_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrIn6Udiqy5n"
      },
      "source": [
        "#### Khai báo datasets object cho 3 bộ train, val, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql6CvvByqy5o"
      },
      "outputs": [],
      "source": [
        "train_dataset = ScenesDataset(\n",
        "    X_train, y_train,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "val_dataset = ScenesDataset(\n",
        "    X_val, y_val,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = ScenesDataset(\n",
        "    X_test, y_test,\n",
        "    transform=transform\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKChhugNqy5o"
      },
      "source": [
        "#### Khai báo dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDXpEISDqy5o"
      },
      "outputs": [],
      "source": [
        "train_batch_size = 512\n",
        "test_batch_size = 8\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=train_batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89bG8OWxqy5o"
      },
      "source": [
        "#### Xây dựng model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVQZmV8rqy5o"
      },
      "outputs": [],
      "source": [
        "class BottleneckBlock(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate) -> None:\n",
        "        super(BottleneckBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.conv1 = nn.Conv2d(in_channels, 4 * growth_rate, kernel_size=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(4 * growth_rate)\n",
        "        self.conv2 = nn.Conv2d(4 * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = x.clone().detach()\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = torch.cat([res, x], 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_layers, in_channels, growth_rate):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        layers = []\n",
        "        for i in range(num_layers):\n",
        "            layers.append(BottleneckBlock(in_channels + i*growth_rate, growth_rate))\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiz8wPoqqy5o"
      },
      "outputs": [],
      "source": [
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, num_blocks, growth_rate, num_classes):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 2 * growth_rate, kernel_size=7,\n",
        "                               padding=3, stride=2, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(2 * growth_rate)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.dense_blocks = nn.ModuleList()\n",
        "        in_channels = 2 * growth_rate\n",
        "        for i, num_layers in enumerate(num_blocks):\n",
        "            self.dense_blocks.append(DenseBlock(num_layers, in_channels, growth_rate))\n",
        "            in_channels += num_layers * growth_rate\n",
        "            if i != len(num_blocks)-1:\n",
        "                out_channels = in_channels // 2\n",
        "                self.dense_blocks.append(nn.Sequential(\n",
        "                    nn.BatchNorm2d(in_channels),\n",
        "                    nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
        "                    nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "                ))\n",
        "                in_channels = out_channels\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
        "        self.pool2 = nn.AvgPool2d(kernel_size=7)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(in_channels, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        for block in self.dense_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ6IakOQqy5o"
      },
      "outputs": [],
      "source": [
        "n_classes = len(list(classes.keys()))\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = DenseNet(\n",
        "    [6, 12, 24, 16],\n",
        "    growth_rate=32,\n",
        "    num_classes=n_classes\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size=(3, 224, 224))"
      ],
      "metadata": {
        "id": "s87iQingq_nH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c842907-7c22-40ba-c7e5-8c3f069d0984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "       BatchNorm2d-5           [-1, 64, 56, 56]             128\n",
            "              ReLU-6           [-1, 64, 56, 56]               0\n",
            "            Conv2d-7          [-1, 128, 56, 56]           8,192\n",
            "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
            "              ReLU-9          [-1, 128, 56, 56]               0\n",
            "           Conv2d-10           [-1, 32, 56, 56]          36,864\n",
            "  BottleneckBlock-11           [-1, 96, 56, 56]               0\n",
            "      BatchNorm2d-12           [-1, 96, 56, 56]             192\n",
            "             ReLU-13           [-1, 96, 56, 56]               0\n",
            "           Conv2d-14          [-1, 128, 56, 56]          12,288\n",
            "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
            "             ReLU-16          [-1, 128, 56, 56]               0\n",
            "           Conv2d-17           [-1, 32, 56, 56]          36,864\n",
            "  BottleneckBlock-18          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-19          [-1, 128, 56, 56]             256\n",
            "             ReLU-20          [-1, 128, 56, 56]               0\n",
            "           Conv2d-21          [-1, 128, 56, 56]          16,384\n",
            "      BatchNorm2d-22          [-1, 128, 56, 56]             256\n",
            "             ReLU-23          [-1, 128, 56, 56]               0\n",
            "           Conv2d-24           [-1, 32, 56, 56]          36,864\n",
            "  BottleneckBlock-25          [-1, 160, 56, 56]               0\n",
            "      BatchNorm2d-26          [-1, 160, 56, 56]             320\n",
            "             ReLU-27          [-1, 160, 56, 56]               0\n",
            "           Conv2d-28          [-1, 128, 56, 56]          20,480\n",
            "      BatchNorm2d-29          [-1, 128, 56, 56]             256\n",
            "             ReLU-30          [-1, 128, 56, 56]               0\n",
            "           Conv2d-31           [-1, 32, 56, 56]          36,864\n",
            "  BottleneckBlock-32          [-1, 192, 56, 56]               0\n",
            "      BatchNorm2d-33          [-1, 192, 56, 56]             384\n",
            "             ReLU-34          [-1, 192, 56, 56]               0\n",
            "           Conv2d-35          [-1, 128, 56, 56]          24,576\n",
            "      BatchNorm2d-36          [-1, 128, 56, 56]             256\n",
            "             ReLU-37          [-1, 128, 56, 56]               0\n",
            "           Conv2d-38           [-1, 32, 56, 56]          36,864\n",
            "  BottleneckBlock-39          [-1, 224, 56, 56]               0\n",
            "      BatchNorm2d-40          [-1, 224, 56, 56]             448\n",
            "             ReLU-41          [-1, 224, 56, 56]               0\n",
            "           Conv2d-42          [-1, 128, 56, 56]          28,672\n",
            "      BatchNorm2d-43          [-1, 128, 56, 56]             256\n",
            "             ReLU-44          [-1, 128, 56, 56]               0\n",
            "           Conv2d-45           [-1, 32, 56, 56]          36,864\n",
            "  BottleneckBlock-46          [-1, 256, 56, 56]               0\n",
            "       DenseBlock-47          [-1, 256, 56, 56]               0\n",
            "      BatchNorm2d-48          [-1, 256, 56, 56]             512\n",
            "           Conv2d-49          [-1, 128, 56, 56]          32,768\n",
            "        AvgPool2d-50          [-1, 128, 28, 28]               0\n",
            "      BatchNorm2d-51          [-1, 128, 28, 28]             256\n",
            "             ReLU-52          [-1, 128, 28, 28]               0\n",
            "           Conv2d-53          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
            "             ReLU-55          [-1, 128, 28, 28]               0\n",
            "           Conv2d-56           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckBlock-57          [-1, 160, 28, 28]               0\n",
            "      BatchNorm2d-58          [-1, 160, 28, 28]             320\n",
            "             ReLU-59          [-1, 160, 28, 28]               0\n",
            "           Conv2d-60          [-1, 128, 28, 28]          20,480\n",
            "      BatchNorm2d-61          [-1, 128, 28, 28]             256\n",
            "             ReLU-62          [-1, 128, 28, 28]               0\n",
            "           Conv2d-63           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckBlock-64          [-1, 192, 28, 28]               0\n",
            "      BatchNorm2d-65          [-1, 192, 28, 28]             384\n",
            "             ReLU-66          [-1, 192, 28, 28]               0\n",
            "           Conv2d-67          [-1, 128, 28, 28]          24,576\n",
            "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
            "             ReLU-69          [-1, 128, 28, 28]               0\n",
            "           Conv2d-70           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckBlock-71          [-1, 224, 28, 28]               0\n",
            "      BatchNorm2d-72          [-1, 224, 28, 28]             448\n",
            "             ReLU-73          [-1, 224, 28, 28]               0\n",
            "           Conv2d-74          [-1, 128, 28, 28]          28,672\n",
            "      BatchNorm2d-75          [-1, 128, 28, 28]             256\n",
            "             ReLU-76          [-1, 128, 28, 28]               0\n",
            "           Conv2d-77           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckBlock-78          [-1, 256, 28, 28]               0\n",
            "      BatchNorm2d-79          [-1, 256, 28, 28]             512\n",
            "             ReLU-80          [-1, 256, 28, 28]               0\n",
            "           Conv2d-81          [-1, 128, 28, 28]          32,768\n",
            "      BatchNorm2d-82          [-1, 128, 28, 28]             256\n",
            "             ReLU-83          [-1, 128, 28, 28]               0\n",
            "           Conv2d-84           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckBlock-85          [-1, 288, 28, 28]               0\n",
            "      BatchNorm2d-86          [-1, 288, 28, 28]             576\n",
            "             ReLU-87          [-1, 288, 28, 28]               0\n",
            "           Conv2d-88          [-1, 128, 28, 28]          36,864\n",
            "      BatchNorm2d-89          [-1, 128, 28, 28]             256\n",
            "             ReLU-90          [-1, 128, 28, 28]               0\n",
            "           Conv2d-91           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckBlock-92          [-1, 320, 28, 28]               0\n",
            "      BatchNorm2d-93          [-1, 320, 28, 28]             640\n",
            "             ReLU-94          [-1, 320, 28, 28]               0\n",
            "           Conv2d-95          [-1, 128, 28, 28]          40,960\n",
            "      BatchNorm2d-96          [-1, 128, 28, 28]             256\n",
            "             ReLU-97          [-1, 128, 28, 28]               0\n",
            "           Conv2d-98           [-1, 32, 28, 28]          36,864\n",
            "  BottleneckBlock-99          [-1, 352, 28, 28]               0\n",
            "     BatchNorm2d-100          [-1, 352, 28, 28]             704\n",
            "            ReLU-101          [-1, 352, 28, 28]               0\n",
            "          Conv2d-102          [-1, 128, 28, 28]          45,056\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Conv2d-105           [-1, 32, 28, 28]          36,864\n",
            " BottleneckBlock-106          [-1, 384, 28, 28]               0\n",
            "     BatchNorm2d-107          [-1, 384, 28, 28]             768\n",
            "            ReLU-108          [-1, 384, 28, 28]               0\n",
            "          Conv2d-109          [-1, 128, 28, 28]          49,152\n",
            "     BatchNorm2d-110          [-1, 128, 28, 28]             256\n",
            "            ReLU-111          [-1, 128, 28, 28]               0\n",
            "          Conv2d-112           [-1, 32, 28, 28]          36,864\n",
            " BottleneckBlock-113          [-1, 416, 28, 28]               0\n",
            "     BatchNorm2d-114          [-1, 416, 28, 28]             832\n",
            "            ReLU-115          [-1, 416, 28, 28]               0\n",
            "          Conv2d-116          [-1, 128, 28, 28]          53,248\n",
            "     BatchNorm2d-117          [-1, 128, 28, 28]             256\n",
            "            ReLU-118          [-1, 128, 28, 28]               0\n",
            "          Conv2d-119           [-1, 32, 28, 28]          36,864\n",
            " BottleneckBlock-120          [-1, 448, 28, 28]               0\n",
            "     BatchNorm2d-121          [-1, 448, 28, 28]             896\n",
            "            ReLU-122          [-1, 448, 28, 28]               0\n",
            "          Conv2d-123          [-1, 128, 28, 28]          57,344\n",
            "     BatchNorm2d-124          [-1, 128, 28, 28]             256\n",
            "            ReLU-125          [-1, 128, 28, 28]               0\n",
            "          Conv2d-126           [-1, 32, 28, 28]          36,864\n",
            " BottleneckBlock-127          [-1, 480, 28, 28]               0\n",
            "     BatchNorm2d-128          [-1, 480, 28, 28]             960\n",
            "            ReLU-129          [-1, 480, 28, 28]               0\n",
            "          Conv2d-130          [-1, 128, 28, 28]          61,440\n",
            "     BatchNorm2d-131          [-1, 128, 28, 28]             256\n",
            "            ReLU-132          [-1, 128, 28, 28]               0\n",
            "          Conv2d-133           [-1, 32, 28, 28]          36,864\n",
            " BottleneckBlock-134          [-1, 512, 28, 28]               0\n",
            "      DenseBlock-135          [-1, 512, 28, 28]               0\n",
            "     BatchNorm2d-136          [-1, 512, 28, 28]           1,024\n",
            "          Conv2d-137          [-1, 256, 28, 28]         131,072\n",
            "       AvgPool2d-138          [-1, 256, 14, 14]               0\n",
            "     BatchNorm2d-139          [-1, 256, 14, 14]             512\n",
            "            ReLU-140          [-1, 256, 14, 14]               0\n",
            "          Conv2d-141          [-1, 128, 14, 14]          32,768\n",
            "     BatchNorm2d-142          [-1, 128, 14, 14]             256\n",
            "            ReLU-143          [-1, 128, 14, 14]               0\n",
            "          Conv2d-144           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-145          [-1, 288, 14, 14]               0\n",
            "     BatchNorm2d-146          [-1, 288, 14, 14]             576\n",
            "            ReLU-147          [-1, 288, 14, 14]               0\n",
            "          Conv2d-148          [-1, 128, 14, 14]          36,864\n",
            "     BatchNorm2d-149          [-1, 128, 14, 14]             256\n",
            "            ReLU-150          [-1, 128, 14, 14]               0\n",
            "          Conv2d-151           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-152          [-1, 320, 14, 14]               0\n",
            "     BatchNorm2d-153          [-1, 320, 14, 14]             640\n",
            "            ReLU-154          [-1, 320, 14, 14]               0\n",
            "          Conv2d-155          [-1, 128, 14, 14]          40,960\n",
            "     BatchNorm2d-156          [-1, 128, 14, 14]             256\n",
            "            ReLU-157          [-1, 128, 14, 14]               0\n",
            "          Conv2d-158           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-159          [-1, 352, 14, 14]               0\n",
            "     BatchNorm2d-160          [-1, 352, 14, 14]             704\n",
            "            ReLU-161          [-1, 352, 14, 14]               0\n",
            "          Conv2d-162          [-1, 128, 14, 14]          45,056\n",
            "     BatchNorm2d-163          [-1, 128, 14, 14]             256\n",
            "            ReLU-164          [-1, 128, 14, 14]               0\n",
            "          Conv2d-165           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-166          [-1, 384, 14, 14]               0\n",
            "     BatchNorm2d-167          [-1, 384, 14, 14]             768\n",
            "            ReLU-168          [-1, 384, 14, 14]               0\n",
            "          Conv2d-169          [-1, 128, 14, 14]          49,152\n",
            "     BatchNorm2d-170          [-1, 128, 14, 14]             256\n",
            "            ReLU-171          [-1, 128, 14, 14]               0\n",
            "          Conv2d-172           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-173          [-1, 416, 14, 14]               0\n",
            "     BatchNorm2d-174          [-1, 416, 14, 14]             832\n",
            "            ReLU-175          [-1, 416, 14, 14]               0\n",
            "          Conv2d-176          [-1, 128, 14, 14]          53,248\n",
            "     BatchNorm2d-177          [-1, 128, 14, 14]             256\n",
            "            ReLU-178          [-1, 128, 14, 14]               0\n",
            "          Conv2d-179           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-180          [-1, 448, 14, 14]               0\n",
            "     BatchNorm2d-181          [-1, 448, 14, 14]             896\n",
            "            ReLU-182          [-1, 448, 14, 14]               0\n",
            "          Conv2d-183          [-1, 128, 14, 14]          57,344\n",
            "     BatchNorm2d-184          [-1, 128, 14, 14]             256\n",
            "            ReLU-185          [-1, 128, 14, 14]               0\n",
            "          Conv2d-186           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-187          [-1, 480, 14, 14]               0\n",
            "     BatchNorm2d-188          [-1, 480, 14, 14]             960\n",
            "            ReLU-189          [-1, 480, 14, 14]               0\n",
            "          Conv2d-190          [-1, 128, 14, 14]          61,440\n",
            "     BatchNorm2d-191          [-1, 128, 14, 14]             256\n",
            "            ReLU-192          [-1, 128, 14, 14]               0\n",
            "          Conv2d-193           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-194          [-1, 512, 14, 14]               0\n",
            "     BatchNorm2d-195          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-196          [-1, 512, 14, 14]               0\n",
            "          Conv2d-197          [-1, 128, 14, 14]          65,536\n",
            "     BatchNorm2d-198          [-1, 128, 14, 14]             256\n",
            "            ReLU-199          [-1, 128, 14, 14]               0\n",
            "          Conv2d-200           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-201          [-1, 544, 14, 14]               0\n",
            "     BatchNorm2d-202          [-1, 544, 14, 14]           1,088\n",
            "            ReLU-203          [-1, 544, 14, 14]               0\n",
            "          Conv2d-204          [-1, 128, 14, 14]          69,632\n",
            "     BatchNorm2d-205          [-1, 128, 14, 14]             256\n",
            "            ReLU-206          [-1, 128, 14, 14]               0\n",
            "          Conv2d-207           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-208          [-1, 576, 14, 14]               0\n",
            "     BatchNorm2d-209          [-1, 576, 14, 14]           1,152\n",
            "            ReLU-210          [-1, 576, 14, 14]               0\n",
            "          Conv2d-211          [-1, 128, 14, 14]          73,728\n",
            "     BatchNorm2d-212          [-1, 128, 14, 14]             256\n",
            "            ReLU-213          [-1, 128, 14, 14]               0\n",
            "          Conv2d-214           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-215          [-1, 608, 14, 14]               0\n",
            "     BatchNorm2d-216          [-1, 608, 14, 14]           1,216\n",
            "            ReLU-217          [-1, 608, 14, 14]               0\n",
            "          Conv2d-218          [-1, 128, 14, 14]          77,824\n",
            "     BatchNorm2d-219          [-1, 128, 14, 14]             256\n",
            "            ReLU-220          [-1, 128, 14, 14]               0\n",
            "          Conv2d-221           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-222          [-1, 640, 14, 14]               0\n",
            "     BatchNorm2d-223          [-1, 640, 14, 14]           1,280\n",
            "            ReLU-224          [-1, 640, 14, 14]               0\n",
            "          Conv2d-225          [-1, 128, 14, 14]          81,920\n",
            "     BatchNorm2d-226          [-1, 128, 14, 14]             256\n",
            "            ReLU-227          [-1, 128, 14, 14]               0\n",
            "          Conv2d-228           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-229          [-1, 672, 14, 14]               0\n",
            "     BatchNorm2d-230          [-1, 672, 14, 14]           1,344\n",
            "            ReLU-231          [-1, 672, 14, 14]               0\n",
            "          Conv2d-232          [-1, 128, 14, 14]          86,016\n",
            "     BatchNorm2d-233          [-1, 128, 14, 14]             256\n",
            "            ReLU-234          [-1, 128, 14, 14]               0\n",
            "          Conv2d-235           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-236          [-1, 704, 14, 14]               0\n",
            "     BatchNorm2d-237          [-1, 704, 14, 14]           1,408\n",
            "            ReLU-238          [-1, 704, 14, 14]               0\n",
            "          Conv2d-239          [-1, 128, 14, 14]          90,112\n",
            "     BatchNorm2d-240          [-1, 128, 14, 14]             256\n",
            "            ReLU-241          [-1, 128, 14, 14]               0\n",
            "          Conv2d-242           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-243          [-1, 736, 14, 14]               0\n",
            "     BatchNorm2d-244          [-1, 736, 14, 14]           1,472\n",
            "            ReLU-245          [-1, 736, 14, 14]               0\n",
            "          Conv2d-246          [-1, 128, 14, 14]          94,208\n",
            "     BatchNorm2d-247          [-1, 128, 14, 14]             256\n",
            "            ReLU-248          [-1, 128, 14, 14]               0\n",
            "          Conv2d-249           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-250          [-1, 768, 14, 14]               0\n",
            "     BatchNorm2d-251          [-1, 768, 14, 14]           1,536\n",
            "            ReLU-252          [-1, 768, 14, 14]               0\n",
            "          Conv2d-253          [-1, 128, 14, 14]          98,304\n",
            "     BatchNorm2d-254          [-1, 128, 14, 14]             256\n",
            "            ReLU-255          [-1, 128, 14, 14]               0\n",
            "          Conv2d-256           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-257          [-1, 800, 14, 14]               0\n",
            "     BatchNorm2d-258          [-1, 800, 14, 14]           1,600\n",
            "            ReLU-259          [-1, 800, 14, 14]               0\n",
            "          Conv2d-260          [-1, 128, 14, 14]         102,400\n",
            "     BatchNorm2d-261          [-1, 128, 14, 14]             256\n",
            "            ReLU-262          [-1, 128, 14, 14]               0\n",
            "          Conv2d-263           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-264          [-1, 832, 14, 14]               0\n",
            "     BatchNorm2d-265          [-1, 832, 14, 14]           1,664\n",
            "            ReLU-266          [-1, 832, 14, 14]               0\n",
            "          Conv2d-267          [-1, 128, 14, 14]         106,496\n",
            "     BatchNorm2d-268          [-1, 128, 14, 14]             256\n",
            "            ReLU-269          [-1, 128, 14, 14]               0\n",
            "          Conv2d-270           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-271          [-1, 864, 14, 14]               0\n",
            "     BatchNorm2d-272          [-1, 864, 14, 14]           1,728\n",
            "            ReLU-273          [-1, 864, 14, 14]               0\n",
            "          Conv2d-274          [-1, 128, 14, 14]         110,592\n",
            "     BatchNorm2d-275          [-1, 128, 14, 14]             256\n",
            "            ReLU-276          [-1, 128, 14, 14]               0\n",
            "          Conv2d-277           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-278          [-1, 896, 14, 14]               0\n",
            "     BatchNorm2d-279          [-1, 896, 14, 14]           1,792\n",
            "            ReLU-280          [-1, 896, 14, 14]               0\n",
            "          Conv2d-281          [-1, 128, 14, 14]         114,688\n",
            "     BatchNorm2d-282          [-1, 128, 14, 14]             256\n",
            "            ReLU-283          [-1, 128, 14, 14]               0\n",
            "          Conv2d-284           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-285          [-1, 928, 14, 14]               0\n",
            "     BatchNorm2d-286          [-1, 928, 14, 14]           1,856\n",
            "            ReLU-287          [-1, 928, 14, 14]               0\n",
            "          Conv2d-288          [-1, 128, 14, 14]         118,784\n",
            "     BatchNorm2d-289          [-1, 128, 14, 14]             256\n",
            "            ReLU-290          [-1, 128, 14, 14]               0\n",
            "          Conv2d-291           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-292          [-1, 960, 14, 14]               0\n",
            "     BatchNorm2d-293          [-1, 960, 14, 14]           1,920\n",
            "            ReLU-294          [-1, 960, 14, 14]               0\n",
            "          Conv2d-295          [-1, 128, 14, 14]         122,880\n",
            "     BatchNorm2d-296          [-1, 128, 14, 14]             256\n",
            "            ReLU-297          [-1, 128, 14, 14]               0\n",
            "          Conv2d-298           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-299          [-1, 992, 14, 14]               0\n",
            "     BatchNorm2d-300          [-1, 992, 14, 14]           1,984\n",
            "            ReLU-301          [-1, 992, 14, 14]               0\n",
            "          Conv2d-302          [-1, 128, 14, 14]         126,976\n",
            "     BatchNorm2d-303          [-1, 128, 14, 14]             256\n",
            "            ReLU-304          [-1, 128, 14, 14]               0\n",
            "          Conv2d-305           [-1, 32, 14, 14]          36,864\n",
            " BottleneckBlock-306         [-1, 1024, 14, 14]               0\n",
            "      DenseBlock-307         [-1, 1024, 14, 14]               0\n",
            "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
            "          Conv2d-309          [-1, 512, 14, 14]         524,288\n",
            "       AvgPool2d-310            [-1, 512, 7, 7]               0\n",
            "     BatchNorm2d-311            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-312            [-1, 512, 7, 7]               0\n",
            "          Conv2d-313            [-1, 128, 7, 7]          65,536\n",
            "     BatchNorm2d-314            [-1, 128, 7, 7]             256\n",
            "            ReLU-315            [-1, 128, 7, 7]               0\n",
            "          Conv2d-316             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-317            [-1, 544, 7, 7]               0\n",
            "     BatchNorm2d-318            [-1, 544, 7, 7]           1,088\n",
            "            ReLU-319            [-1, 544, 7, 7]               0\n",
            "          Conv2d-320            [-1, 128, 7, 7]          69,632\n",
            "     BatchNorm2d-321            [-1, 128, 7, 7]             256\n",
            "            ReLU-322            [-1, 128, 7, 7]               0\n",
            "          Conv2d-323             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-324            [-1, 576, 7, 7]               0\n",
            "     BatchNorm2d-325            [-1, 576, 7, 7]           1,152\n",
            "            ReLU-326            [-1, 576, 7, 7]               0\n",
            "          Conv2d-327            [-1, 128, 7, 7]          73,728\n",
            "     BatchNorm2d-328            [-1, 128, 7, 7]             256\n",
            "            ReLU-329            [-1, 128, 7, 7]               0\n",
            "          Conv2d-330             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-331            [-1, 608, 7, 7]               0\n",
            "     BatchNorm2d-332            [-1, 608, 7, 7]           1,216\n",
            "            ReLU-333            [-1, 608, 7, 7]               0\n",
            "          Conv2d-334            [-1, 128, 7, 7]          77,824\n",
            "     BatchNorm2d-335            [-1, 128, 7, 7]             256\n",
            "            ReLU-336            [-1, 128, 7, 7]               0\n",
            "          Conv2d-337             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-338            [-1, 640, 7, 7]               0\n",
            "     BatchNorm2d-339            [-1, 640, 7, 7]           1,280\n",
            "            ReLU-340            [-1, 640, 7, 7]               0\n",
            "          Conv2d-341            [-1, 128, 7, 7]          81,920\n",
            "     BatchNorm2d-342            [-1, 128, 7, 7]             256\n",
            "            ReLU-343            [-1, 128, 7, 7]               0\n",
            "          Conv2d-344             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-345            [-1, 672, 7, 7]               0\n",
            "     BatchNorm2d-346            [-1, 672, 7, 7]           1,344\n",
            "            ReLU-347            [-1, 672, 7, 7]               0\n",
            "          Conv2d-348            [-1, 128, 7, 7]          86,016\n",
            "     BatchNorm2d-349            [-1, 128, 7, 7]             256\n",
            "            ReLU-350            [-1, 128, 7, 7]               0\n",
            "          Conv2d-351             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-352            [-1, 704, 7, 7]               0\n",
            "     BatchNorm2d-353            [-1, 704, 7, 7]           1,408\n",
            "            ReLU-354            [-1, 704, 7, 7]               0\n",
            "          Conv2d-355            [-1, 128, 7, 7]          90,112\n",
            "     BatchNorm2d-356            [-1, 128, 7, 7]             256\n",
            "            ReLU-357            [-1, 128, 7, 7]               0\n",
            "          Conv2d-358             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-359            [-1, 736, 7, 7]               0\n",
            "     BatchNorm2d-360            [-1, 736, 7, 7]           1,472\n",
            "            ReLU-361            [-1, 736, 7, 7]               0\n",
            "          Conv2d-362            [-1, 128, 7, 7]          94,208\n",
            "     BatchNorm2d-363            [-1, 128, 7, 7]             256\n",
            "            ReLU-364            [-1, 128, 7, 7]               0\n",
            "          Conv2d-365             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-366            [-1, 768, 7, 7]               0\n",
            "     BatchNorm2d-367            [-1, 768, 7, 7]           1,536\n",
            "            ReLU-368            [-1, 768, 7, 7]               0\n",
            "          Conv2d-369            [-1, 128, 7, 7]          98,304\n",
            "     BatchNorm2d-370            [-1, 128, 7, 7]             256\n",
            "            ReLU-371            [-1, 128, 7, 7]               0\n",
            "          Conv2d-372             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-373            [-1, 800, 7, 7]               0\n",
            "     BatchNorm2d-374            [-1, 800, 7, 7]           1,600\n",
            "            ReLU-375            [-1, 800, 7, 7]               0\n",
            "          Conv2d-376            [-1, 128, 7, 7]         102,400\n",
            "     BatchNorm2d-377            [-1, 128, 7, 7]             256\n",
            "            ReLU-378            [-1, 128, 7, 7]               0\n",
            "          Conv2d-379             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-380            [-1, 832, 7, 7]               0\n",
            "     BatchNorm2d-381            [-1, 832, 7, 7]           1,664\n",
            "            ReLU-382            [-1, 832, 7, 7]               0\n",
            "          Conv2d-383            [-1, 128, 7, 7]         106,496\n",
            "     BatchNorm2d-384            [-1, 128, 7, 7]             256\n",
            "            ReLU-385            [-1, 128, 7, 7]               0\n",
            "          Conv2d-386             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-387            [-1, 864, 7, 7]               0\n",
            "     BatchNorm2d-388            [-1, 864, 7, 7]           1,728\n",
            "            ReLU-389            [-1, 864, 7, 7]               0\n",
            "          Conv2d-390            [-1, 128, 7, 7]         110,592\n",
            "     BatchNorm2d-391            [-1, 128, 7, 7]             256\n",
            "            ReLU-392            [-1, 128, 7, 7]               0\n",
            "          Conv2d-393             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-394            [-1, 896, 7, 7]               0\n",
            "     BatchNorm2d-395            [-1, 896, 7, 7]           1,792\n",
            "            ReLU-396            [-1, 896, 7, 7]               0\n",
            "          Conv2d-397            [-1, 128, 7, 7]         114,688\n",
            "     BatchNorm2d-398            [-1, 128, 7, 7]             256\n",
            "            ReLU-399            [-1, 128, 7, 7]               0\n",
            "          Conv2d-400             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-401            [-1, 928, 7, 7]               0\n",
            "     BatchNorm2d-402            [-1, 928, 7, 7]           1,856\n",
            "            ReLU-403            [-1, 928, 7, 7]               0\n",
            "          Conv2d-404            [-1, 128, 7, 7]         118,784\n",
            "     BatchNorm2d-405            [-1, 128, 7, 7]             256\n",
            "            ReLU-406            [-1, 128, 7, 7]               0\n",
            "          Conv2d-407             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-408            [-1, 960, 7, 7]               0\n",
            "     BatchNorm2d-409            [-1, 960, 7, 7]           1,920\n",
            "            ReLU-410            [-1, 960, 7, 7]               0\n",
            "          Conv2d-411            [-1, 128, 7, 7]         122,880\n",
            "     BatchNorm2d-412            [-1, 128, 7, 7]             256\n",
            "            ReLU-413            [-1, 128, 7, 7]               0\n",
            "          Conv2d-414             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-415            [-1, 992, 7, 7]               0\n",
            "     BatchNorm2d-416            [-1, 992, 7, 7]           1,984\n",
            "            ReLU-417            [-1, 992, 7, 7]               0\n",
            "          Conv2d-418            [-1, 128, 7, 7]         126,976\n",
            "     BatchNorm2d-419            [-1, 128, 7, 7]             256\n",
            "            ReLU-420            [-1, 128, 7, 7]               0\n",
            "          Conv2d-421             [-1, 32, 7, 7]          36,864\n",
            " BottleneckBlock-422           [-1, 1024, 7, 7]               0\n",
            "      DenseBlock-423           [-1, 1024, 7, 7]               0\n",
            "     BatchNorm2d-424           [-1, 1024, 7, 7]           2,048\n",
            "            ReLU-425           [-1, 1024, 7, 7]               0\n",
            "       AvgPool2d-426           [-1, 1024, 1, 1]               0\n",
            "          Linear-427                    [-1, 6]           6,150\n",
            "================================================================\n",
            "Total params: 6,960,006\n",
            "Trainable params: 6,960,006\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 372.58\n",
            "Params size (MB): 26.55\n",
            "Estimated Total Size (MB): 399.70\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJEBtqc3qy5o"
      },
      "source": [
        "#### Xây dựng hàm đánh giá model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj0XI6WYqy5o"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            losses.append(loss.item())\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    loss = sum(losses) /  len(losses)\n",
        "    acc = correct / total\n",
        "    return loss, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9qCSB-Cqy5o"
      },
      "source": [
        "#### Xây dựng hàm huấn luyện model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSVhnApHqy5p"
      },
      "outputs": [],
      "source": [
        "def fit(model, train_loader, val_loader, criterion, optimizer, device, epochs):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        batch_train_losses = []\n",
        "\n",
        "        model.train()\n",
        "        for idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_train_losses.append(loss.item())\n",
        "\n",
        "        train_loss = sum(batch_train_losses) / len(batch_train_losses)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f'EPOCH {epoch + 1}:\\tTrain loss: {train_loss:.4f}\\tVal loss: {val_loss:.4f}')\n",
        "\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIVdXq-Hqy5p"
      },
      "source": [
        "#### Khai báo hàm loss và thuật toán tối ưu hóa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcIbcEa_qy5p"
      },
      "outputs": [],
      "source": [
        "lr = 1e-2\n",
        "epochs = 15\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=lr\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfgoRc-6qy5p"
      },
      "source": [
        "#### Thực hiện huấn luyện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyVKEAY3qy5p"
      },
      "outputs": [],
      "source": [
        "train_losses, val_losses = fit(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    device,\n",
        "    epochs\n",
        ")\n",
        "\n",
        "# save weights model\n",
        "torch.save(model.state_dict(), 'weather_classification_weights.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqptmLTCqy5p"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 8))\n",
        "\n",
        "ax[0].plot(train_losses)\n",
        "ax[0].set_title('Training Loss')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[0].set_ylabel('Loss')\n",
        "\n",
        "ax[1].plot(val_losses, color='orange')\n",
        "ax[1].set_title('Val Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MbbYxQlqy5p"
      },
      "source": [
        "#### Đánh giá mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIeh_YWLqy5p"
      },
      "outputs": [],
      "source": [
        "val_loss, val_acc = evaluate(\n",
        "    model,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    device\n",
        ")\n",
        "test_loss, test_acc = evaluate(\n",
        "    model,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    device\n",
        ")\n",
        "\n",
        "print('Evaluate on val/test dataset')\n",
        "print('Val accuracy: ', val_acc)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}